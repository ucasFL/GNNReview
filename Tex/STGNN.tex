\subsection{时空图神经网络}
在现实世界的许多应用中，图形无论是在图形结构还是在图形输入方面都是动态的。时空图神经网络(STGNNs)在捕捉图的动态性方面占有重要地位。这类方法的目的是在假设连接节点之间相互依赖的情况下，对动态节点输入进行建模。例如，交通网络中节点由放置在道路上的速度传感器组成，边权重由传感器对之间的距离决定。由于一条道路的交通状况可能取决于其相邻道路的状况，因此在进行交通速度预测时必须考虑空间相关性。作为一种解决方案，STGNNs同时捕获图的空间和时间依赖关系。STGNNs的任务可以是预测未来的节点值或标签，或者预测时空图标签。STGNNs遵循两个方向：基于RNN的方法和基于CNN的方法。

基于RNN的方法：基于RNN的方法通过使用图形卷积过滤输入和隐藏状态来捕获时空依赖性。为了说明这一点，假设一个简单的RNN采用这种形式
\[
H^{(t)}=\delta(WX^{(t)}+UH^{(t)}+b)
\]
其中，$X^{(t)}\in R^{n\times d}$是时间$t$步的节点特征矩阵，插入图卷积后，上式变为
\[
H^{(t)}=\delta(Gconv(X^{(t)},A;W)+Gconv(H^{(t-1)},A;U)+b)
\]
其中，Gconv为图卷积层。

Structural-RNN \cite{jain2016structural}提出了一个递归框架来预测每个时间步的节点标签。它包括两种RNN，即节点-RNN和边缘RNN。每个节点和每个边的时间信息分别通过节点-RNN和边缘-RNN。为了合并空间信息，节点-RNN将边-RNN的输出作为输入。由于为不同的节点和边缘假定不同的RNN会显着增加模型的复杂性，因此它将节点和边缘分成语义组。同一语义组中的节点或边共享相同的RNN模型，从而节省了计算成本。基于RNN的方法会有耗时的迭代和梯度爆炸/消失问题，特别是在结合ConvGNN时比较显著。

作为替代的方法，基于CNN的方法通过非递归的几乎等效的计算，稳定的梯度和较低的存储需要来解决时空图问题。

基于CNN的方法：
通过一个一维的图卷积层来分别学习时间和空间的依赖关系。假设一个图时空网络的输入是张量$\mathcal{X}\in R^{T \times n \times d}$,在图卷积层在$\mathcal{X}_{[i,:,:]}$收集信息时，一维的图卷积层沿着时间轴，依次滑过$\mathcal{X}_{[:，i,:]}$来为每个节点收集信息。CGCN\cite{yu2017spatio}使一维卷积层通过CheNet或者GCN一体化，通过叠加按顺序排列的一个门控一维卷积层，一个图卷积层和另外一个门控一维卷积层来构建一个时间块。ST-GCN\cite{yan2018spatial}使用一个一维卷积层和一个PGC层组成一个时间块。前面的方法都是使用预定义的图结构，他们假设预定义的图结构反应了节点间真正的依赖关系。然而，由于在时空环境中有许多图形数据快照，因此可以从数据中自动学习潜在的静态图形结构。为了实现这一目的，
Graph WaveNet\cite{wu2019graph}提出了一种自适应邻接矩阵来执行图卷积。
自适应邻接矩阵定义为
\[
A_{adp}=SoftMax(ReLU(E_1E_2^T))
\]
其中E1表示源节点嵌入，E2表示嵌入可学习参数的目标节点。通过将E1与E2相乘，可以获得从源节点到目标节点的依赖性权重。利用复杂的基于CNN的时空神经网络，Graph WaveNet在没有给出邻接矩阵的情况下表现良好。

通过学习隐藏的静态空间依赖性的意义在于，可以帮助研究人员发现网络中不同实体之间的可解释和稳定的相关性。然而，在某些情况下，学习潜在的动态空间依赖性可以进一步提高模型精度。例如，在交通网络中，两条道路之间的行程时间可能取决于它们当前的交通条件。GaAN [48]采用注意机制通过基于RNN的方法学习动态空间依赖性。该功能用于在给定其当前节点输入的情况下更新两个连接节点之间的边缘权重。ASTGCN\cite{guo2019attention}采纳了空间注意功能和时间注意功能，以通过基于CNN的方法来学习潜在的动态空间依赖性和时间依赖性。学习潜在空间依赖性的共同缺点是它需要计算每对节点之间的空间依赖性权重，其时间复杂度为$O(n^2)$





